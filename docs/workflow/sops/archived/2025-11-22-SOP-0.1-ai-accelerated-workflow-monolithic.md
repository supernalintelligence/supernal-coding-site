# SOP-0.1: AI-Accelerated Workflow

**Purpose**: Core principles and practical strategies for working effectively with AI in software development  
**Scope**: All AI-assisted development work across all phases  
**Audience**: Developers, architects, product managers working with AI coding assistants

---

## Table of Contents

**Part 1: Foundation**

1. [Core Principle](#1-core-principle)
2. [When to Use AI vs Not](#2-when-to-use-ai-vs-not)
3. [AI's Role in Development](#3-ais-role-in-development)

**Part 2: Chat Management** 4. [Chat Isolation Strategy](#4-chat-isolation-strategy) 5. [Context Establishment](#5-context-establishment) 6. [Progressive Summarization](#6-progressive-summarization)

**Part 3: Planning Workflow** 7. [Planning Hierarchy](#7-planning-hierarchy) 8. [Approval Gates](#8-approval-gates) 9. [Documentation Patterns](#9-documentation-patterns)

**Part 4: Prompting Patterns** 10. [Investigation Prompts](#10-investigation-prompts) 11. [Planning Prompts](#11-planning-prompts) 12. [Clarification Prompts](#12-clarification-prompts) 13. [Simplification Prompts](#13-simplification-prompts) 14. [Re-evaluation Prompts](#14-re-evaluation-prompts)

**Part 5: Architecture & Organization** 15. [Separation Strategies](#15-separation-strategies) 16. [Coupling Principles](#16-coupling-principles) 17. [Pattern Consistency](#17-pattern-consistency) 18. [Change Management](#18-change-management)

**Part 6: Validation & Quality** 19. [Multi-Agent Validation](#19-multi-agent-validation) 20. [Verification Checklists](#20-verification-checklists) 21. [Iterative Refinement](#21-iterative-refinement)

**Part 7: Quality Automation & Git Workflow** 22. [AI Pitfalls & Prevention](#22-ai-pitfalls--prevention) 23. [Automated Testing Strategy](#23-automated-testing-strategy) 24. [Git Branching & Commit Strategy](#24-git-branching--commit-strategy) 25. [Merge Strategy with sc git-smart](#25-merge-strategy-with-sc-git-smart) 26. [Approval Workflows (Fast-Paced)](#26-approval-workflows-fast-paced-collaboration)

---

# Part 1: Foundation

## 1. Core Principle

**AI accelerates development when given clear context and structured tasks.**

### What AI Does Well

âœ… **Research & Intelligence**

- Gather best practices, patterns, libraries
- Compare approaches with trade-offs
- Find security/performance considerations

âœ… **Planning & Design**

- Propose system architectures
- Design component structures
- Model data relationships
- Map out file/folder organization

âœ… **Code Generation**

- Generate boilerplate following patterns
- Create type definitions
- Write test scaffolding
- Produce documentation

âœ… **Analysis & Review**

- Review code for issues
- Investigate bugs
- Analyze performance
- Audit security

### What AI Doesn't Do Well

âŒ **Critical Decisions**

- Business logic correctness (Person must verify)
- Security architecture (Person must review)
- Compliance requirements (Person must approve)
- Trade-off decisions (Person makes final call)

âŒ **Execution**

- Production deployments (Person executes)
- Data migrations (Person oversees)
- Credential management (Person handles)
- Risk acceptance (Person decides)

### The Acceleration Pattern

```
1. Person defines problem/goal
2. AI researches and proposes solutions
3. Person evaluates, questions, refines
4. AI generates detailed plan
5. Appropriate team approves
6. AI generates code
7. Person reviews and tests
8. Iterate until complete
```

**Key**: AI proposes, Person/team approves, AI executes, Person verifies

---

## 2. When to Use AI vs Not

### âœ… Use AI For

**Discovery & Research**

- "What are current best practices for [X]?"
- "Compare [A] vs [B] for [use case]"
- "What security concerns exist for [feature]?"
- "Research open source/closed source solutions for [problem]"

**Planning & Architecture**

- "Propose system architecture for [feature]"
- "Design data model for [domain]"
- "Plan file/folder structure for [component]"
- "Outline API endpoints for [service]"

**Implementation**

- "Generate [component] following [pattern]"
- "Create tests for [module]"
- "Write documentation for [API]"
- "Implement [feature] according to [plan]"

**Analysis & Improvement**

- "Review this code for issues"
- "Find performance bottlenecks"
- "Suggest simplifications"
- "Identify security vulnerabilities"

### âŒ Don't Use AI For

**Judgment Calls**

- Priority setting (Person decides)
- Timeline commitments (Person estimates)
- Resource allocation (Person manages)
- Risk acceptance (Person evaluates)

**Sensitive Operations**

- Production data access (Person controls)
- User PII handling (Person oversees)
- Financial transactions (Person executes)
- Security credentials (Person manages)

**Blind Execution**

- Running code without understanding it
- Accepting first output without review
- Implementing without planning
- Deploying without testing

---

## 3. AI's Role in Development

### AI as Research Assistant

**Pattern**: Person asks questions â†’ AI researches â†’ Person evaluates

```
Person: "What's the best way to handle real-time collaboration?"
AI: [Researches CRDTs, OT, WebSockets, WebRTC]
AI: [Presents options with trade-offs]
Person: [Evaluates based on requirements]
Person: "Let's use WebSockets with operational transform"
```

### AI as Design Partner

**Pattern**: Person defines requirements â†’ AI proposes designs â†’ Team refines

```
Person: "We need user authentication with social login"
AI: [Proposes architecture: OAuth, JWT, session management]
Team: [Reviews, questions, refines]
Team: [Approves design]
AI: [Generates implementation plan]
```

### AI as Implementation Accelerator

**Pattern**: Plan approved â†’ AI generates code â†’ Person reviews â†’ Iterate

```
[Plan approved]
Person: "Implement auth service per approved plan"
AI: [Generates code following patterns]
Person: [Reviews, tests, requests changes]
AI: [Refines based on feedback]
Person: [Approves, merges]
```

### AI as Quality Checker

**Pattern**: Code complete â†’ AI reviews â†’ Person addresses issues

```
Person: "Review this authentication implementation"
AI: [Finds issues: missing rate limiting, weak token validation]
Person: [Evaluates criticality, prioritizes fixes]
Person: "Add rate limiting, keep token validation"
AI: [Implements fixes]
```

---

# Part 2: Chat Management

## 4. Chat Isolation Strategy

### When to Start New Chat

**Start new chat when**:

1. **Starting different feature/epic**
   - Completely separate functionality
   - Different domain context
   - New architectural decisions

2. **Need fresh perspective**
   - Validation/review of existing work
   - Second opinion on approach
   - Design alternatives

3. **Context has drifted**
   - Chat approaches 80% token usage after summarization
   - AI starts behaving oddly
   - Producing incorrect/inconsistent results
   - Too many tangents from original goal

4. **Handoff to different role**
   - Implementation â†’ Review
   - Backend â†’ Frontend
   - Development â†’ Testing

### When to Continue Same Chat

**Continue chat when**:

1. **Iterating on same feature**
   - Refinement and debugging
   - Building on previous decisions
   - Consistent context valuable

2. **Sequential phases**
   - Planning â†’ Implementation
   - Implementation â†’ Testing
   - Testing â†’ Documentation

3. **Troubleshooting**
   - Debugging specific issue
   - Fixing failing tests
   - Resolving errors

### The Cost of Context Switching

**New chat**:

- âœ… Fresh perspective
- âœ… No accumulated confusion
- âŒ Must re-establish context
- âŒ Loses implementation history

**Same chat**:

- âœ… Maintains context
- âœ… Remembers decisions
- âŒ Can accumulate errors
- âŒ Token usage grows

**Rule**: Use same chat until context becomes burden, then start fresh

---

## 5. Context Establishment

### Starting New Chat: Context Template

```markdown
[New Chat]

## Context

**Working On**: [Feature/Epic name]

**System**: [Brief system description]

**Already Complete**:

- [What's implemented]
- [Key decisions made]

**Current Task**: [Specific goal for this chat]

**Constraints**:

- Tech stack: [languages, frameworks]
- Patterns: [architectural patterns in use]
- Requirements: [must-haves for this task]

**Relevant Files**:

- [file/path/one.ts] - [what it does]
- [file/path/two.ts] - [what it does]

**Documentation**:

- See [docs/architecture/decisions/001-auth.md] for auth approach
- See [docs/features/user-management/planning/plan.md] for feature plan

## Task

[Specific thing you need AI to do]
```

### Why This Works

**AI gets**:

- âœ… Full context without reading entire history
- âœ… Clear constraints and requirements
- âœ… Pointers to relevant documentation
- âœ… Specific, actionable task

**You get**:

- âœ… Focused responses
- âœ… Consistent with existing patterns
- âœ… Less back-and-forth clarification

### Reusing Context Across Chats

**Save reusable context in**:

- `docs/architecture/decisions/` - ADRs
- `docs/architecture/domain-model.md` - Domain concepts
- `docs/features/\{feature\}/planning/` - Feature plans
- `.cursor/rules/` - Coding patterns
- `docs/reference/system-context.md` - System overview

**Reference in new chats**:

- "See [file] for [context]"
- "Follow pattern from [file]"
- "Based on decision in [ADR]"

---

## 6. Progressive Summarization

### Managing Long Chats

**When chat exceeds ~50 messages**:

1. **Request summary**:

   ```
   "Summarize our conversation:
   - Key decisions made
   - Current implementation status
   - Outstanding tasks
   - Important context to preserve"
   ```

2. **Save summary** to feature documentation

3. **Continue or start fresh**:
   - If < 80% token usage â†’ continue
   - If â‰¥ 80% token usage â†’ new chat with summary

### Summary Template

```markdown
# Chat Summary: [Feature] - [Date]

## Key Decisions

- [Decision 1 and rationale]
- [Decision 2 and rationale]

## Current Status

- âœ… Completed: [what's done]
- ğŸ”„ In Progress: [what's being worked on]
- â¸ï¸ Blocked: [what's waiting]

## Technical Details

- Architecture: [approach taken]
- Patterns: [patterns used]
- Dependencies: [key dependencies]

## Outstanding Tasks

- [ ] [Task 1]
- [ ] [Task 2]

## Context for Next Chat

[Critical information needed to continue]
```

---

# Part 3: Planning Workflow

## 7. Planning Hierarchy

### The Five-Level Planning Model

```
Level 1: System Architecture
  â†“ (AI proposes â†’ Team evaluates, questions, refines â†’ Team approves)

Level 2: Feature Breakdown
  â†“ (AI proposes â†’ Team evaluates, questions, refines â†’ Team approves)

Level 3: Component Design
  â†“ (Person + AI proposes â†’ Team evaluates, questions, refines â†’ Team approves)

Level 4: Implementation Plan
  â†“ (AI proposes â†’ Person/pair reviews â†’ Approves)

Level 5: Code Generation
  â†“ (AI generates â†’ Person reviews â†’ Tests â†’ Approves)
```

**Never skip levels.** Each level must be approved before next.

### Level 1: System Architecture

**What**: High-level system design

**Includes**:

- Major components and boundaries
- Technology choices
- Integration points
- Deployment architecture
- Security model

**Who Approves**: Tech lead + architect + relevant stakeholders

**Output**: Architecture Decision Records (ADRs)

**Example Question**: "Should we use microservices or modular monolith?"

### Level 2: Feature Breakdown

**What**: Decompose feature into implementable chunks

**Includes**:

- User-facing capabilities
- Backend services needed
- Data model changes
- API endpoints
- UI components

**Who Approves**: Product + engineering lead

**Output**: Feature plan with epics/stories

**Example Question**: "How do we split 'user authentication' into stories?"

### Level 3: Component Design

**What**: Detailed component architecture

**Includes**:

- Component responsibilities
- Interfaces/contracts
- Data flow
- State management
- Error handling

**Who Approves**: Engineering team

**Output**: Component design doc

**Example Question**: "How should AuthService interact with UserService?"

### Level 4: Implementation Plan

**What**: Specific implementation approach

**Includes**:

- File/folder structure
- Class/function names
- Module organization
- Test strategy
- Migration plan

**Who Approves**: Developer + pair/lead

**Output**: Implementation checklist

**Example Question**: "Which files need changes for OAuth integration?"

### Level 5: Code Generation

**What**: Actual code

**Includes**:

- Implementation code
- Tests
- Documentation
- Type definitions

**Who Approves**: Developer (via review + tests)

**Output**: Working, tested code

---

## 8. Approval Gates

### What Must Be Approved Before Implementation

**Critical Elements**:

- âœ… **Names**: Entities, models, services, routes, functions
- âœ… **Types**: Data structures, interfaces, enums, schemas
- âœ… **Containers**: Components, modules, packages, directories
- âœ… **Modals**: UI patterns, state management, workflows
- âœ… **Routes**: URL structure, API endpoints, navigation
- âœ… **Test Data**: Fixtures, mocks, test scenarios
- âœ… **Coupling**: How systems interact, dependencies
- âœ… **Separation**: Layer boundaries, front-end/back-end split

### Why Approval Gates Matter

**Changing names later impacts**:

- Multiple files
- Database migrations
- API contracts
- Documentation
- Tests

**Cost**: Hours to days of refactoring

**Prevention**: Get it right first

### Approval Process

```
1. AI + Person proposes complete system plan
2. Team reviews ALL names, types, structure
3. Team asks clarifying questions:
   - "Why this name vs that name?"
   - "How does this integrate with existing?"
   - "What happens if we need to extend?"
4. Team requests refinements
5. AI revises based on feedback
6. Repeat until team approves
7. Plan becomes reference doc
8. Implementation follows plan
```

### Approval Checklist

**Before approving plan**:

- [ ] All names are clear and consistent
- [ ] Follows existing naming conventions
- [ ] Types are appropriate for data
- [ ] Integrations are well-defined
- [ ] Error handling is considered
- [ ] Test strategy is outlined
- [ ] Migration path is clear (if applicable)
- [ ] Team has no more questions

---

## 9. Documentation Patterns

### Code in Plans: When and How

**Code is easier to write than pseudocode**, so plans often include code.

**When to include code**:

- âœ… Interface contracts (APIs, types)
- âœ… Pattern demonstrations
- âœ… Complex logic that's hard to describe

**When NOT to include code**:

- âŒ Full implementations (wasteful)
- âŒ Code that will be regenerated
- âŒ Anything that might change

### Extractable Code Pattern

**If writing complete code in docs**, use extraction-friendly format:

````markdown
## File: src/services/auth.service.ts

```typescript
// This code can be extracted using sc extract-code or text extraction tools

export interface AuthService {
  login(email: string, password: string): Promise<AuthToken>;
  logout(token: string): Promise<void>;
  verify(token: string): Promise<User>;
}

export class AuthServiceImpl implements AuthService {
  async login(email: string, password: string): Promise<AuthToken> {
    // Implementation
  }

  async logout(token: string): Promise<void> {
    // Implementation
  }

  async verify(token: string): Promise<User> {
    // Implementation
  }
}
```

**Usage**: Run `sc extract-code plan.md` to extract into files
````

### Plan Documentation Structure

```markdown
# Feature: [Name]

## 1. Overview

[What we're building and why]

## 2. Architecture

[High-level design, diagrams]

## 3. Components

### Component A

- Responsibility: [what it does]
- Interface: [API/contract]
- Dependencies: [what it needs]

## 4. Data Model

[Types, schemas, migrations]

## 5. API Endpoints

[Routes, request/response formats]

## 6. Implementation Checklist

- [ ] Task 1
- [ ] Task 2

## 7. Test Strategy

[What to test, how to test]

## 8. Deployment

[How to deploy, rollback plan]
```

---

# Part 4: Prompting Patterns

## 10. Investigation Prompts

### Research Pattern

```
"Research [topic]:

Context:
- We're building [system]
- Current approach: [what we're doing now]
- Problem: [what's not working]

Investigation:
- What are current best practices?
- What open source / closed source solutions exist?
- What packages/libraries are commonly used?
- What patterns are recommended?
- What security concerns exist?
- What performance implications?

Provide:
- Options with trade-offs
- Recommendations with rationale
- Sources/references"
```

### Competitor Intelligence Pattern

```
"Analyze [competitors/solutions] for [feature]:

Investigate:
- Open source projects doing [similar thing]
- Closed source products with [feature]
- Common patterns across solutions
- Innovative approaches
- What works well
- What doesn't work well

Provide:
- Feature comparison table
- Pattern analysis
- Recommendations for our implementation"
```

### Example Usage

```
"Research real-time collaboration solutions:

Context:
- Building document editor
- Need multi-user simultaneous editing
- Must handle conflicts

Investigation:
- OT vs CRDT approaches
- WebSocket vs WebRTC
- Yjs, Automerge, ShareDB packages
- Conflict resolution strategies
- Performance at scale

Provide options with trade-offs."
```

---

## 11. Planning Prompts

### System Architecture Pattern

```
"Design system architecture for [feature]:

Requirements:
- [Requirement 1]
- [Requirement 2]

Constraints:
- Tech stack: [technologies]
- Scale: [expected load]
- Budget: [cost constraints]

Provide:
- Component diagram
- Responsibility breakdown
- Integration points
- Data flow
- Technology recommendations
- Trade-offs"
```

### Implementation Planning Pattern

```
"Create implementation plan for [feature]:

Context:
- Architecture: [approved architecture]
- Existing code: [relevant files]
- Patterns: [patterns to follow]

Plan:
- File/folder structure
- Components to create/modify
- Order of implementation
- Test strategy
- Migration steps (if applicable)

Show plan first, don't generate code yet."
```

### Example Usage

```
"Design authentication system:

Requirements:
- Email/password login
- OAuth (Google, GitHub)
- JWT tokens
- Refresh token rotation

Constraints:
- Node.js + Express
- PostgreSQL
- Redis for sessions
- Must be GDPR compliant

Provide complete architecture plan."
```

---

## 12. Clarification Prompts

### Understanding Pattern

```
"Explain [concept/code]:

What I don't understand:
- [Specific confusion point]

Help me understand:
- What problem does this solve?
- How does it work?
- Why this approach vs alternatives?
- What are the trade-offs?
- How does it integrate with [related component]?"
```

### Code Review Pattern

```
"Review this code and explain:

[Code snippet]

Questions:
- What does this do?
- Why is it structured this way?
- What could go wrong?
- How could it be improved?
- Are there edge cases not handled?"
```

### Example Usage

```
"Explain this authentication flow:

[Code showing OAuth redirect handling]

I don't understand:
- Why do we need state parameter?
- What's the security risk without it?
- How does it prevent CSRF?
- Are there other security considerations?"
```

---

## 13. Simplification Prompts

### Complexity Reduction Pattern

```
"Simplify this [code/design]:

[Current approach]

This feels too complex because:
- [Reason 1]
- [Reason 2]

Analyze:
- Identify unnecessary complexity
- Propose simpler alternatives
- Show what can be eliminated
- Explain trade-offs

Goal: Simplest solution that works."
```

### Refactoring Pattern

```
"Refactor [code/component]:

Current issues:
- [Issue 1]
- [Issue 2]

Desired:
- More readable
- Easier to test
- Fewer dependencies
- Better separation of concerns

Show before/after with explanation."
```

### Example Usage

```
"Simplify this authentication middleware:

[Current middleware with 200 lines]

Too complex because:
- Mixes authorization and authentication
- Hard to test
- Lots of nested conditionals

Propose simpler approach with better separation."
```

---

## 14. Re-evaluation Prompts

### Critical Review Pattern

```
"Critically review [plan/code]:

[Current approach]

Analyze:
- Potential bugs
- Security vulnerabilities
- Performance issues
- Maintainability concerns
- Better approaches

Be harsh. What would fail in production?"
```

### Second Opinion Pattern

```
"Second opinion on [decision]:

Decision made:
- [What was decided]
- [Rationale]

Challenge this:
- What are we missing?
- What could go wrong?
- Are there better alternatives?
- What assumptions are we making?

Play devil's advocate."
```

### Example Usage

```
"Review this authentication design:

[Design doc]

Critically analyze:
- Security: What attacks are possible?
- Performance: Where are bottlenecks?
- Scalability: What breaks at scale?
- Maintainability: What's hard to change?

What would you do differently?"
```

---

# Part 5: Architecture & Organization

## 15. Separation Strategies

### Layer Separation (Recommended)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API Layer         â”‚  â† HTTP, GraphQL, RPC
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Business Layer    â”‚  â† Domain logic, workflows
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Data Layer        â”‚  â† Database, cache, external APIs
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Benefits**:

- Layers work independently
- Can develop/test in parallel
- Clear contracts between layers
- Easy to replace implementations

**Example**:

```typescript
// API Layer (routes/auth.routes.ts)
router.post('/login', authController.login);

// Business Layer (services/auth.service.ts)
class AuthService {
  async login(email: string, password: string): Promise<AuthToken> {
    // Business logic
  }
}

// Data Layer (repositories/user.repository.ts)
class UserRepository {
  async findByEmail(email: string): Promise<User | null> {
    // Database query
  }
}
```

### Front-end/Back-end Separation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend   â”‚ â†â”€â”€â”€â”€â”€â”€â†’ â”‚   Backend    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            API Contract
      (OpenAPI / GraphQL Schema)
```

**Benefits**:

- Independent development
- Different deployment cycles
- Clear interface
- Team parallelization

**API Contract First**:

1. Define API contract (OpenAPI spec)
2. Frontend mocks API
3. Backend implements API
4. Integration testing verifies contract

### Event-Driven Separation

```
Component A  â”€â”€â†’  Message Bus  â†â”€â”€  Component B
     â†‘                                    â†“
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              (Decoupled communication)
```

**When to use**:

- Async processing
- Scalability requirements
- Loose coupling needed
- Event sourcing

---

## 16. Coupling Principles

### When Tight Coupling is OK

**Acceptable tight coupling**:

- Components that always change together
- Strong domain relationship (Order â†’ OrderItem)
- Performance critical (avoiding indirection)
- Small, cohesive modules

**Example**:

```typescript
// OK: Order and OrderItem tightly coupled
class Order {
  items: OrderItem[];

  addItem(item: OrderItem) {
    this.items.push(item);
    this.recalculateTotal();
  }
}
```

### When Loose Coupling Required

**Require loose coupling**:

- Multiple teams
- Independent deployment
- Different change frequencies
- External integrations

**Example**:

```typescript
// Good: Payment service loosely coupled via interface
interface PaymentGateway {
  charge(amount: Money): Promise<PaymentResult>;
}

class OrderService {
  constructor(private paymentGateway: PaymentGateway) {}

  async checkout(order: Order): Promise<void> {
    await this.paymentGateway.charge(order.total);
  }
}
```

### Dependency Direction

**Rule**: Dependencies point inward (toward business logic)

```
API Layer â”€â”€â†’ Business Layer â†â”€â”€ Data Layer
                    â†‘
              (Core domain)
```

**Why**: Business logic should not depend on infrastructure

---

## 17. Pattern Consistency

### Following Established Patterns

**Before generating code**:

1. âœ… Check existing patterns in codebase
2. âœ… Ask: "Should I follow pattern from [existing file]?"
3. âœ… Generate code matching the pattern
4. âœ… Verify consistency with linter/formatter

**Example Prompt**:

```
"Generate UserService following the pattern in AuthService:
- Same error handling
- Same logging approach
- Same dependency injection
- Same test structure"
```

### When to Deviate from Patterns

**OK to deviate when**:

- Pattern is inappropriate for use case
- New pattern is significantly better
- Team discusses and approves change

**Process**:

1. Identify why current pattern doesn't fit
2. Propose new pattern with rationale
3. Team evaluates trade-offs
4. Team approves or rejects
5. If approved, document new pattern

**Not OK**:

- "This way seems better" (without analysis)
- Mixing multiple patterns
- Individual preference without team buy-in

### Pattern Documentation

**Document patterns in**:

- `.cursor/rules/` - For AI awareness
- `docs/reference/patterns/` - For team reference
- Code comments - For inline guidance

**Pattern doc structure**:

```markdown
# Pattern: [Name]

## When to Use

[Specific scenarios]

## Structure

[Code example]

## Trade-offs

[Pros and cons]

## Examples

[Links to usage in codebase]
```

---

## 18. Change Management

### Avoiding Breaking Changes

**Before changing**:

- [ ] Find all usages (`grep`, find references)
- [ ] Identify impact (which files, which teams)
- [ ] Create migration plan
- [ ] Discuss with affected teams
- [ ] Get approval for breaking change

**Process**:

1. **Parallel implementation** (old + new coexist)
2. **Gradual migration** (update usages one by one)
3. **Deprecation warning** (mark old as deprecated)
4. **Cutover period** (both work)
5. **Remove old** (after all migrated)

### Non-Breaking Change Pattern

**Add new, deprecate old**:

```typescript
// Old (deprecated)
/** @deprecated Use authenticateUser instead */
function authenticate(credentials: any): Promise<User> {
  return authenticateUser(credentials);
}

// New (recommended)
function authenticateUser(credentials: Credentials): Promise<User> {
  // Implementation
}
```

### Breaking Change Pattern

**When breaking change is necessary**:

1. Announce change to team
2. Document migration guide
3. Provide codemod/migration script if possible
4. Set deprecation timeline
5. Monitor migration progress
6. Remove old after deadline

**Migration guide template**:

````markdown
# Migration: Old API â†’ New API

## What Changed

[Explanation]

## Why

[Rationale]

## How to Migrate

### Before

```typescript
// Old code
```
````

### After

```typescript
// New code
```

## Timeline

- [Date]: Deprecation announced
- [Date]: New API available
- [Date]: Old API removed

```

---

# Part 6: Validation & Quality

## 19. Multi-Agent Validation

### When to Use Second Opinion

**Use different chat/AI for**:
- Major architectural decisions
- Security-critical code
- Complex algorithms
- Unfamiliar technology
- High-risk changes
- Compliance requirements

### Second Opinion Pattern

```

[Chat 1: Implementation]
Person: "Implement authentication system"
AI: [Generates solution]

[Chat 2: Review - Fresh Context]
Person: "Review this authentication implementation:
[Paste code/design]

Look for:

- Security vulnerabilities
- Performance issues
- Maintainability concerns
- Better approaches

Be critical."

AI: [Provides critical feedback]

[Back to Chat 1]
Person: "Reviewer found issues:

- [Issue 1]
- [Issue 2]

Address these."

AI: [Implements fixes]

```

### Multi-Model Strategy

**When available, use different models**:
- **Primary implementation**: Claude, GPT-4, etc.
- **Security review**: Specialized model or fresh instance
- **Code review**: Different model for fresh perspective
- **Architecture review**: Third opinion on major decisions

**Why**: Different models/instances catch different issues

### Team Validation

**Critical decisions validated by**:
- Pair programming
- Team review
- Architecture review board
- Security team
- Compliance team

**AI provides draft, humans make decision**

---

## 20. Verification Checklists

### For Plans

**Before approving plan**:
- [ ] All names are clear and follow conventions
- [ ] Types are appropriate for data
- [ ] Structure makes sense
- [ ] Integrations are well-defined
- [ ] Edge cases considered
- [ ] Error handling planned
- [ ] Test strategy included
- [ ] Migration path clear (if applicable)
- [ ] Team has reviewed and approved
- [ ] No outstanding questions

### For Code

**Before merging code**:
- [ ] Follows existing patterns
- [ ] All tests pass
- [ ] No linter errors
- [ ] Type-checks successfully
- [ ] Code review completed
- [ ] Edge cases handled
- [ ] Error handling present
- [ ] Logging appropriate
- [ ] Documentation updated
- [ ] Person has reviewed and approved

### For Research

**Before acting on research**:
- [ ] Sources cited
- [ ] Multiple independent sources
- [ ] Recent information (if time-sensitive)
- [ ] Conclusions supported by evidence
- [ ] Alternatives considered
- [ ] Trade-offs analyzed
- [ ] Applicable to our context
- [ ] Team agrees with assessment

### For Architecture

**Before implementing architecture**:
- [ ] Solves stated problem
- [ ] Scales to requirements
- [ ] Fits existing system
- [ ] Technology choices justified
- [ ] Security considered
- [ ] Performance analyzed
- [ ] Cost estimated
- [ ] Team has expertise (or plan to gain it)
- [ ] Risks identified and mitigated
- [ ] Alternative approaches considered

---

## 21. Iterative Refinement

### The Refinement Loop

```

1. AI proposes solution
2. Person reviews critically
3. Person requests specific changes
4. AI refines based on feedback
5. Repeat until approved

```

**Never accept first output.** AI's first response is a draft.

### Questions to Ask Every Time

**For any AI output**:
- "Can this be simpler?"
- "What's missing?"
- "What could go wrong?"
- "Any better approaches?"
- "What are the trade-offs?"
- "Does this follow our patterns?"

### Refinement Prompts

**Simplification**:
```

"This is too complex. Simplify by:

- Removing [specific complexity]
- Consolidating [specific duplication]
- Clarifying [specific confusion]"

```

**Missing Elements**:
```

"Add:

- Error handling for [scenario]
- Tests for [edge case]
- Documentation for [component]"

```

**Alternative Approaches**:
```

"Show 3 alternative approaches:

1. Current approach
2. Simpler but [trade-off]
3. More complex but [benefit]

Compare trade-offs."

````

### Knowing When to Stop

**Refinement is complete when**:
- âœ… Solves stated problem
- âœ… No obvious improvements remain
- âœ… Team approves
- âœ… Tests pass
- âœ… Meets quality standards
- âœ… Documented appropriately

**Don't over-refine**:
- âŒ Perfect is enemy of done
- âŒ Diminishing returns
- âŒ Delaying unnecessarily

**Rule**: "Good enough to ship" beats "perfect in theory"

---

# Part 7: Quality Automation & Git Workflow

## 22. AI Pitfalls & Prevention

### The Duplication Problem

**AI's biggest pitfall**: Creating new implementations of things that already exist

**Why it happens**:
- AI doesn't see full codebase context
- Similar names in different locations
- Patterns exist but aren't obvious
- AI defaults to "create new" vs "find existing"

**Cost**:
- Duplicate logic (maintenance nightmare)
- Inconsistent behavior (different implementations)
- Wasted effort (reimplementing existing)
- Confused codebase (which one to use?)

### Prevention Strategy: Audit Before Implement

**Before implementing ANY feature**:

#### Step 1: Name & Pattern Audit

```bash
# Search for similar names
grep -r "ClassName" --include="*.ts" --include="*.js"
grep -r "functionName" --include="*.ts" --include="*.js"
grep -r "interface.*Name" --include="*.ts" --include="*.js"

# Search for similar patterns
grep -r "authentication\|auth\|login" --include="*.ts"
grep -r "validation\|validate\|validator" --include="*.ts"
````

**Ask AI**:

```
"Before implementing [feature], search the codebase for:
- Similar class names
- Similar function names
- Similar patterns or implementations
- Existing utilities we can reuse

Show me what already exists that might solve this problem."
```

#### Step 2: Location Verification

**Common mistake**: Creating in wrong location

**Correct locations**:

```
src/
â”œâ”€â”€ services/        â† Business logic services
â”œâ”€â”€ utils/           â† Utility functions
â”œâ”€â”€ components/      â† UI components
â”œâ”€â”€ hooks/           â† React hooks
â”œâ”€â”€ lib/             â† Third-party integrations
â”œâ”€â”€ types/           â† TypeScript types
â”œâ”€â”€ constants/       â† Constants and enums
â””â”€â”€ config/          â† Configuration
```

**Before creating**:

```
"Where should [ClassName] be located?
Check existing structure:
- Are there similar classes?
- Which directory do they live in?
- Should this be in the same location?

Show me the correct location based on existing patterns."
```

#### Step 3: Name Duplication Check

**Run name collision check**:

```bash
# Check if name already exists
find . -name "*AuthService*" -type f
find . -name "*Validator*" -type f
find . -name "*Helper*" -type f

# Check class/interface names in code
grep -r "class AuthService" --include="*.ts"
grep -r "interface IAuthService" --include="*.ts"
grep -r "export.*AuthService" --include="*.ts"
```

**Ask AI**:

```
"Is the name 'AuthService' already used?
Search for:
- class AuthService
- interface AuthService
- type AuthService
- export { AuthService }

If it exists, show me:
- Where it's defined
- What it does
- Should I reuse it or create a different name?"
```

### Prevention Checklist

**Before implementing, verify**:

- [ ] Searched for similar names (`grep -r "ClassName"`)
- [ ] Searched for similar functionality (`grep -r "feature"`)
- [ ] Checked correct location (matches existing patterns)
- [ ] No name collisions (unique names)
- [ ] Reviewed existing implementations (can reuse?)
- [ ] Asked AI to find duplicates
- [ ] Confirmed with team (if uncertain)

### AI Prompt Pattern for Prevention

**Use this pattern BEFORE generating code**:

```
"I need to implement [feature/class/function].

BEFORE generating code, help me avoid duplication:

1. Search Analysis:
   - Search codebase for similar names
   - Search for similar functionality
   - Find existing implementations we can reuse

2. Location Analysis:
   - Where do similar classes/functions live?
   - What's the correct location for this?
   - Show me the directory structure

3. Duplication Check:
   - Does this name already exist?
   - Are there similar implementations?
   - Can we reuse or extend existing code?

4. Recommendation:
   - Should I create new or reuse existing?
   - If new, what name avoids collisions?
   - If reuse, which existing code?

ONLY generate code after this analysis."
```

### Example: Preventing Duplication

**âŒ BAD (No audit)**:

```
Person: "Create a user validation service"
AI: [Generates new UserValidationService]
# Oops! UserValidator already exists in src/validators/
```

**âœ… GOOD (With audit)**:

```
Person: "Create a user validation service.

BEFORE generating:
1. Search for existing validation code
2. Check where validators are located
3. Find similar implementations"

AI: "Found existing code:
- src/validators/UserValidator.ts (handles user validation)
- src/validators/EmailValidator.ts (similar pattern)
- src/services/ValidationService.ts (orchestrates validators)

Recommendation: Extend existing UserValidator instead of creating new service."

Person: "Good catch! Extend UserValidator with [new feature]"
AI: [Extends existing code]
```

### Linting & Validation Tools

**We use ESLint** (standard JavaScript/TypeScript linter):

**Configuration**:

- Root: `.eslintrc.js` (project-wide rules)
- Dashboard: `apps/supernal-dashboard/.eslintrc.json` (app-specific)

**Run linting**:

```bash
# Lint all files
npm run lint

# Lint specific files
npx eslint src/services/auth.service.ts

# Auto-fix issues
npm run lint -- --fix
```

**Pre-commit hooks run ESLint automatically**:

```bash
sc git-hooks install

# Now every commit automatically:
# âœ… ESLint checks code quality
# âœ… Prettier formats code
# âœ… TypeScript checks types
```

### Name Collision Detection

**Built-in TypeScript checks**:

```typescript
// TypeScript catches duplicate declarations
class AuthService {}
class AuthService {} // âŒ Error: Duplicate identifier
```

**But doesn't catch across files**:

```typescript
// src/services/auth.service.ts
export class AuthService {}

// src/utils/auth.service.ts
export class AuthService {} // âš ï¸ No error, but confusing!
```

**Manual check required**:

```bash
# Find all AuthService exports
grep -r "export.*AuthService" --include="*.ts"

# Find all AuthService classes
grep -r "class AuthService" --include="*.ts"
```

### Pattern Analysis Tool

**Use codebase search to find patterns**:

```bash
# Find all service classes
grep -r "class.*Service" --include="*.ts"

# Find all validator classes
grep -r "class.*Validator" --include="*.ts"

# Find all hook implementations
find src/hooks -name "use*.ts"

# Find all API routes
find src/app/api -name "route.ts"
```

**Ask AI to analyze patterns**:

```
"Analyze the codebase structure:

1. How are services organized?
   - Find all *Service classes
   - Where are they located?
   - What's the naming pattern?

2. What's the pattern for validators?
   - Find all *Validator classes
   - How are they structured?
   - What conventions are used?

3. Where should I put my new [ClassName]?
   Based on existing patterns."
```

### Real-World Prevention Example

**Scenario**: Need to implement email validation

**Step 1: Search**:

```bash
grep -r "email.*valid" --include="*.ts" -i

# Found:
# src/utils/emailValidator.ts
# src/validators/EmailValidator.ts
# src/lib/validation/email.ts
```

**Step 2: Analyze**:

```
Person: "Found 3 email validation implementations:
1. src/utils/emailValidator.ts
2. src/validators/EmailValidator.ts
3. src/lib/validation/email.ts

Which should I use? Are these duplicates?"

AI: [Analyzes each file]
"Analysis:
1. utils/emailValidator.ts - Old, deprecated
2. validators/EmailValidator.ts - Current, comprehensive
3. lib/validation/email.ts - Third-party wrapper

Recommendation: Use validators/EmailValidator.ts
Deprecate utils/emailValidator.ts"
```

**Step 3: Clean up**:

```bash
# Move old implementation to deprecated
git mv src/utils/emailValidator.ts src/utils/_deprecated_emailValidator.ts

# Update all imports to use canonical validator
# [Update references]

# Document canonical location
echo "Email validation: Use src/validators/EmailValidator.ts" >> docs/reference/validators.md
```

### Documentation: Canonical Locations

**Maintain a reference doc**:

```markdown
# Canonical Implementations

## Validation

- Email: `src/validators/EmailValidator.ts`
- Password: `src/validators/PasswordValidator.ts`
- User: `src/validators/UserValidator.ts`

## Services

- Auth: `src/services/auth/AuthService.ts`
- User: `src/services/user/UserService.ts`
- Email: `src/services/email/EmailService.ts`

## Utilities

- String: `src/utils/string.ts`
- Date: `src/utils/date.ts`
- Format: `src/utils/format.ts`

## When adding new code:

1. Check this list first
2. If similar exists, extend it
3. If new, add to this list
4. Update this doc with location
```

---

## 23. Automated Testing Strategy

### Testing is Core to AI-Accelerated Development

**Why testing matters MORE with AI**:

- AI generates code quickly
- Humans can't manually verify everything
- Automated tests catch AI mistakes
- Enables fast iteration with confidence

### Three Layers of Testing

```
1. Pre-commit hooks    â† Local, fast, prevent bad commits
2. Pre-push hooks       â† Local, comprehensive, prevent bad pushes
3. GitHub workflows     â† External, complete, prevent bad merges
```

### Layer 1: Pre-Commit Hooks

**Install once**:

```bash
sc git-hooks install
```

**What they do**:

- âœ… Lint code (ESLint, Prettier)
- âœ… Type-check (TypeScript)
- âœ… Run fast unit tests (< 10 seconds)
- âœ… Validate commit message format
- âœ… Check for sensitive data (secrets, keys)

**When they run**: Every `git commit`

**Why they matter**: Catch issues BEFORE they enter history

**Example**:

```bash
git add src/auth.service.ts
git commit -m "Add login"

# Pre-commit hook runs:
# âœ… ESLint passed
# âœ… TypeScript check passed
# âœ… Unit tests passed (3 tests, 0.8s)
# âœ… Commit message OK
# Commit succeeded
```

### Layer 2: Pre-Push Hooks

**What they do**:

- âœ… Run full test suite
- âœ… Integration tests
- âœ… Build verification
- âœ… Security checks (npm audit)
- âœ… Documentation validation

**When they run**: Every `git push`

**Why they matter**: Comprehensive validation before sharing code

**Example**:

```bash
git push origin feature/auth-login

# Pre-push hook runs:
# âœ… All tests passed (127 tests, 12.3s)
# âœ… Build successful
# âœ… No security vulnerabilities
# âœ… Documentation valid
# Push succeeded
```

### Layer 3: GitHub Workflows (CI/CD)

**What they do**:

- âœ… Run tests in clean environment
- âœ… Multi-platform testing (Linux, macOS, Windows)
- âœ… Cross-version testing (Node 18, 20, 22)
- âœ… End-to-end tests
- âœ… Deploy to staging/preview
- âœ… Performance benchmarks
- âœ… Security scanning

**When they run**: Every push, every PR

**Why they matter**: External validation, no local environment issues

**Example**:

```yaml
# .github/workflows/test.yml
name: Test Suite
on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: npm ci
      - run: npm test
      - run: npm run build
```

### Never Bypass Hooks (Except Emergency)

**âŒ BAD**:

```bash
git commit --no-verify  # Skips pre-commit hooks
git push --no-verify    # Skips pre-push hooks
```

**Why**: Bypassing hooks defeats automated quality

**When to bypass** (rare):

- Emergency hotfix (fix production outage)
- Hook is broken (fix the hook first)
- Metadata-only commit (documentation, no code)

**If you must bypass**:

```bash
# Document WHY in commit message
git commit --no-verify -m "docs: Update README

BYPASS REASON: Documentation only, no code changes"
```

### Test-Driven with AI

**Pattern**:

1. Write test (or have AI write test from requirements)
2. Run test (fails, as expected)
3. AI generates implementation
4. Run test (passes)
5. Refactor if needed
6. Commit when green

**Example**:

```typescript
// 1. Test first (AI generates from requirement)
describe('AuthService.login', () => {
  it('should return token for valid credentials', async () => {
    const token = await authService.login('user@example.com', 'password');
    expect(token).toBeDefined();
    expect(token.expiresAt).toBeGreaterThan(Date.now());
  });
});

// 2. Run test (RED)
// âŒ Test failed: login method not implemented

// 3. AI implements
// 4. Run test (GREEN)
// âœ… Test passed

// 5. Commit
git add src/auth.service.ts tests/auth.service.test.ts
git commit -m "feat: Add AuthService.login method"
```

---

## 24. Git Branching & Commit Strategy

### Branch Naming Convention (sc git-smart)

**Feature branches**:

```bash
feature/req-XXX-brief-description
feature/add-user-authentication
feature/implement-oauth-login
```

**Epic branches** (multiple features):

```bash
epic/epic-name-major-feature
epic/user-management-system
epic/payment-integration
```

**Hotfix branches** (production fixes):

```bash
hotfix/critical-issue-description
hotfix/fix-auth-token-expiry
hotfix/patch-security-vulnerability
```

**Documentation branches**:

```bash
docs/update-description
docs/add-api-reference
docs/update-sop-workflow
```

**Why naming matters**: Clear intent, easy filtering, requirement traceability

### One Feature Per Commit (Preferred)

**Good commit**:

```bash
# Single feature, complete, tested
git add src/auth.service.ts tests/auth.service.test.ts
git commit -m "feat: Add login method with JWT tokens

- Implements email/password authentication
- Returns JWT access token + refresh token
- Includes rate limiting (5 attempts per minute)
- Adds comprehensive tests

REQ-042"
```

**Why**: Atomic changes, easy revert, clear history

### Multiple Features Per Branch (Same System)

**When appropriate**:

- Features are closely related
- Share same domain/system
- Logically grouped together
- All part of same epic/milestone

**Example**:

```bash
# Branch: feature/epic-auth-complete
git commit -m "feat: Add login endpoint (REQ-042)"
git commit -m "feat: Add logout endpoint (REQ-043)"
git commit -m "feat: Add token refresh (REQ-044)"
git commit -m "feat: Add password reset (REQ-045)"
```

**Why**: Easier testing, integrated deployment, related features

### Commit Message Format

**Structure**:

```
<type>: <subject>

<body>

<footer>
```

**Types**:

- `feat:` - New feature
- `fix:` - Bug fix
- `refactor:` - Code restructuring
- `docs:` - Documentation only
- `test:` - Adding/updating tests
- `chore:` - Maintenance (dependencies, config)

**Example**:

```bash
git commit -m "feat: Implement OAuth 2.0 login flow

Add Google and GitHub OAuth providers with PKCE flow.
Includes state validation and CSRF protection.

Changes:
- Add OAuthService with provider abstraction
- Implement callback handler with security checks
- Add OAuth configuration management
- Include comprehensive integration tests

REQ-038, REQ-039
Closes #123"
```

### What to Commit Together

**âœ… DO commit together**:

- Implementation + tests for same feature
- Code + related documentation updates
- Multiple files for same logical change
- Configuration + code that depends on it

**âŒ DON'T commit together**:

- Multiple unrelated features
- Work-in-progress + complete features
- Experimental code + production code
- Code + unrelated documentation

---

## 25. Merge Strategy with sc git-smart

### Using sc git-smart merge

**Safe merge with automation**:

```bash
# Check branch status first
sc git-smart check-branch

# Safe merge with validation
sc git-smart merge --push --delete-local
```

**What sc git-smart merge does**:

1. âœ… Validates branch state
2. âœ… Updates main branch
3. âœ… Rebases feature branch on main
4. âœ… Runs tests
5. âœ… Merges with --no-ff
6. âœ… Pushes to remote (if --push)
7. âœ… Deletes local branch (if --delete-local)
8. âœ… Updates requirement status

### Pre-Merge Checklist

**Before merging**:

- [ ] All commits related to feature/requirement
- [ ] Feature branch up to date with main
- [ ] All tests pass locally
- [ ] Pre-push hooks pass
- [ ] GitHub workflow checks green
- [ ] Code reviewed (if team requires)
- [ ] Documentation updated
- [ ] No merge conflicts

### Merge Workflow

```bash
# 1. Final testing
npm test
npm run build

# 2. Check branch readiness
sc git-smart check-branch

# 3. Safe merge
sc git-smart merge --push --delete-local

# Output:
# âœ… Branch validated
# âœ… Main branch updated
# âœ… Rebase successful
# âœ… Tests passed
# âœ… Merge completed
# âœ… Pushed to remote
# âœ… Local branch deleted
# âœ… Requirement REQ-042 updated to 'merged'
```

### Conflict Resolution

**When conflicts occur**:

1. **Pause**: Don't auto-resolve
2. **Analyze**: Understand both changes
3. **Resolve**: Manual edit to preserve intent
4. **Test**: Ensure merged code works
5. **Document**: Comment on complex resolutions

**Example**:

```bash
# Conflict during rebase
git rebase main

# CONFLICT in src/auth.service.ts
# <<<<<<< HEAD (main)
# Old implementation
# =======
# Your implementation
# >>>>>>> feature/auth-login

# 1. Edit file to resolve
# 2. Test resolution
npm test

# 3. Continue rebase
git add src/auth.service.ts
git rebase --continue

# 4. Complete merge
sc git-smart merge --push
```

---

## 26. Approval Workflows (Fast-Paced Collaboration)

### The Approval Challenge

**Problem**: Multiple approvals slow down velocity

**Solution**: Tiered approval strategy

### Approval Tiers

#### Tier 1: Technical Validation (Automated)

**Always required** (no bypass):

- âœ… Tests pass
- âœ… Lints clean
- âœ… Builds successfully
- âœ… Security checks pass
- âœ… Type-checks pass

**Who approves**: Automated (hooks + CI)

**Blocks**: Cannot merge if fails

#### Tier 2: Code Quality (AI + Human)

**Required for**:

- Implementation code
- Business logic
- API changes

**Who reviews**:

1. AI review first (pattern check, security audit)
2. Human spot-check (sample review, critical paths)

**Pattern**:

```bash
# 1. AI review
Person: "Review this implementation for issues"
AI: [Provides feedback]
Person: [Addresses issues]

# 2. Human spot-check (async)
# Merge proceeds, human reviews post-merge
# Issues found â†’ follow-up PR

# 3. Commit
git commit -m "feat: Add feature

AI-reviewed: Security, patterns, edge cases
Human-review: Deferred to post-merge"
```

**Why**: AI catches most issues, human review async

#### Tier 3: Architectural Decisions (Team Approval)

**Required for**:

- System architecture changes
- Major refactors
- Breaking API changes
- Security-critical code
- New technology adoption

**Who approves**: Tech lead + relevant team members

**Pattern**:

```markdown
# Architecture Decision Record (ADR)

## Status: Proposed â†’ Under Review â†’ Approved

## Decision

[What we're doing]

## Rationale

[Why we're doing it]

## Alternatives Considered

[What we didn't choose and why]

## Consequences

[Trade-offs]

## Approval

- [x] Tech Lead: @username (Approved 2024-11-22)
- [x] Backend Team: @team (Approved 2024-11-22)
- [ ] Security Team: @security (Pending)
```

**Blocks**: Implementation waits for approval

#### Tier 4: Business/Product Decisions (Stakeholder Approval)

**Required for**:

- User-facing features
- Data model changes
- Workflow changes
- Compliance requirements

**Who approves**: Product owner + stakeholders

**Pattern**: Gherkin scenarios + approval

```gherkin
Feature: User Authentication

  Scenario: User logs in with email
    Given I am on the login page
    When I enter valid credentials
    Then I should be logged in

Status: âœ… Approved by Product (2024-11-22)
Status: âœ… Approved by Security (2024-11-22)
Status: ğŸ”„ Implementation in progress
```

### Fast-Track Approval (Post-Facto)

**When to use**:

- Low-risk changes (documentation, tests)
- Urgent fixes (hotfix, production issue)
- Experimental features (behind feature flag)
- Internal tools (not user-facing)

**Process**:

1. **Implement with AI review**
2. **Pass automated checks**
3. **Merge with notification**
4. **Team reviews post-merge**
5. **Follow-up PR if issues found**

**Example**:

```bash
# 1. AI review
# [AI feedback, implementation]

# 2. Automated checks pass
npm test  # âœ…
npm run build  # âœ…

# 3. Merge with notification
git commit -m "feat: Add user profile caching

Tier 2 approval: AI-reviewed, post-facto human review requested
Low risk: Behind feature flag, fully tested
Notification: @team-backend for post-merge review"

sc git-smart merge --push

# 4. Notify team
# [Slack/Email: "New feature merged, please review when available"]

# 5. Follow-up if needed
# [Team reviews, creates follow-up PR if issues]
```

**Fast-track checklist**:

- [ ] AI review completed
- [ ] All automated checks pass
- [ ] Low risk or behind feature flag
- [ ] Team notified for post-merge review
- [ ] Ready to revert if issues found

### Balancing Speed vs Safety

**High speed, lower risk**: Post-facto approval

- Documentation changes
- Test additions
- Internal tools
- Feature-flagged experiments

**High safety, may be slower**: Pre-merge approval

- Production database migrations
- Security changes
- Breaking API changes
- Compliance-related code

### Emergency Override Process

**When**: Production outage, critical security fix

**Process**:

1. Fix implemented
2. AI review (quick check)
3. Automated tests (if possible)
4. Merge with `--no-verify` (if hooks block)
5. Immediate post-deploy verification
6. Team notification
7. Retrospective (why emergency, how to prevent)

**Example**:

```bash
# Production auth service down
git checkout -b hotfix/auth-token-validation
# [Implement fix]

npm test  # âœ… Tests pass

git commit -m "hotfix: Fix auth token validation causing 500s

EMERGENCY: Production outage
Bypassing: Pre-push hooks (time-critical)
AI-reviewed: Security check passed
Deployed to: Production immediately
Notification: @team, @oncall

Retrospective: Scheduled for 2024-11-23"

git push origin hotfix/auth-token-validation --no-verify

# Deploy immediately
# [Deploy process]

# Notify team
# [Incident report, retrospective scheduled]
```

---

## Summary: AI-Accelerated Workflow

### The Complete Flow

```

1. Person defines problem/goal
2. AI researches and proposes solutions
3. Person + Team evaluate, question, refine
4. AI generates detailed plan
5. Appropriate team approves plan
6. AI generates code following approved plan
7. Person reviews, tests, validates
8. Iterate refinements
9. Person approves for merge
10. Repeat for next task

```

### Key Principles

1. **Plan before code** (system â†’ feature â†’ component â†’ implementation â†’ code)
2. **Isolate chats strategically** (new context vs continuity)
3. **Approve architecture first** (names, types, structure before code)
4. **Audit before implement** (search for duplicates, verify location, check names)
5. **Use patterns consistently** (follow existing, don't reinvent)
6. **Validate with multiple perspectives** (second opinion for critical decisions)
7. **Verify systematically** (checklists for plans, code, research)
8. **Iterate and refine** (first output is draft, not final)
9. **Team approves, Person verifies** (humans make decisions, AI accelerates)
10. **Test automatically** (pre-commit, pre-push, CI/CD)
11. **Commit atomically** (one feature per commit, clear history)
12. **Merge safely** (use `sc git-smart merge`, never force push)
13. **Fast-track low-risk** (post-facto approval for speed)

### Anti-Patterns to Avoid

âŒ Implementing before planning
âŒ Accepting first AI output without review
âŒ Skipping approval gates
âŒ Changing names/structure mid-implementation
âŒ Using AI for critical decisions without human approval
âŒ Working without clear requirements
âŒ Generating code that doesn't follow existing patterns
âŒ Creating duplicates of existing code (audit first!)
âŒ Creating in wrong location (verify structure first)
âŒ Name collisions (check for duplicates)
âŒ Bypassing git hooks (--no-verify) except emergencies
âŒ Committing untested code
âŒ Force pushing to main/master
âŒ Merging without CI checks passing

### Success Metrics

**You're doing it right when**:

- AI saves time (not creates rework)
- Code follows existing patterns
- Plans are approved before implementation
- Team understands what AI generated
- Changes don't break existing code
- Quality standards are maintained
- Development velocity increases
- All commits pass automated checks
- Git history is clean and traceable
- Merges happen safely without incidents
- Low-risk changes ship quickly with post-facto review
- High-risk changes get proper pre-merge approval

---

## Related SOPs

- [SOP-0: Complete Development Workflow](../SOP-0-overview-complete-workflow.md)
- [SOP-0.01: Business Vision & Problem](archived - see phase-0-discovery/)
- [SOP-T.01: Using `sc` CLI](../tools/SOP-T.01-using-sc-cli.md)

```

```
